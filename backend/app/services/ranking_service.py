"""
ãƒ©ãƒ³ã‚­ãƒ³ã‚°é›†è¨ˆã‚µãƒ¼ãƒ“ã‚¹ï¼ˆQiitaè¨˜äº‹ãƒ™ãƒ¼ã‚¹ï¼‰
"""

import logging
import math
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import func, text

from ..models.book import Book, BookQiitaMention
from ..models.qiita_article import QiitaArticle
from ..services.openbd_service import get_openbd_service
from ..services.cache_service import get_cache_service

logger = logging.getLogger(__name__)


class RankingService:
    """Qiitaè¨˜äº‹ãƒ™ãƒ¼ã‚¹ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°é›†è¨ˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, db: Session):
        self.db = db
        self.openbd_service = get_openbd_service()
        self.cache = get_cache_service()
    
    def get_ranking_fast(
        self,
        tags: Optional[List[str]] = None,
        days: Optional[int] = None,
        year: Optional[int] = None,
        month: Optional[int] = None,
        limit: Optional[int] = 100,
        offset: Optional[int] = None,
        search: Optional[str] = None
    ) -> Dict:
        """
        é«˜é€Ÿãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ï¼ˆç›´æ¥SQLä½¿ç”¨ã€top_articlesã‚‚2ã‚¯ã‚¨ãƒªã§åŠ¹ç‡å–å¾—ï¼‰
        
        NEONãªã©ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ã„ç’°å¢ƒã§ã‚‚é«˜é€Ÿå‹•ä½œ
        
        Args:
            tags: ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
            days: éå»Næ—¥é–“
            year: å¹´ãƒ•ã‚£ãƒ«ã‚¿
            month: æœˆãƒ•ã‚£ãƒ«ã‚¿
            limit: å–å¾—ä»¶æ•°ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
            offset: ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
            search: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ›¸ç±åã€è‘—è€…ã€å‡ºç‰ˆç¤¾ï¼‰
        
        Returns:
            ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ç·ä»¶æ•°
        
        ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥:
        - æ¤œç´¢ãªã—ãƒ»å…¨ä»¶: 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        - æ¤œç´¢ã‚ã‚Š: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ï¼‰
        - ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ã‚Š: 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        """
        # æ¤œç´¢çµæœã‚‚çŸ­æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåŒã˜æ¤œç´¢ã®é‡è¤‡ã‚’é˜²ãï¼‰
        use_cache = True  # å¸¸ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚å«ã‚ã‚‹ï¼‰
        cache_key_params = {
            "tags": tuple(sorted(tags)) if tags else None,
            "days": days,
            "year": year,
            "month": month,
            "limit": limit,
            "offset": offset,
            "search": search,  # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«å«ã‚ã‚‹
        }
        cache_key = self.cache._generate_key("ranking_fast", **cache_key_params)
            
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            logger.info(f"âœ… ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key[:50]}...")
            return cached_result
        
        logger.info(f"ğŸ” ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€DBã‚¯ã‚¨ãƒªå®Ÿè¡Œ: {cache_key[:50]}...")
        # æœŸé–“æ¡ä»¶ã‚’æ§‹ç¯‰
        date_condition = ""
        if days is not None:
            start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
            date_condition = f"AND qa.published_at >= '{start_date}'"
        elif year is not None and month is not None:
            import calendar
            last_day = calendar.monthrange(year, month)[1]
            date_condition = f"AND qa.published_at >= '{year}-{month:02d}-01' AND qa.published_at <= '{year}-{month:02d}-{last_day}'"
        elif year is not None:
            date_condition = f"AND qa.published_at >= '{year}-01-01' AND qa.published_at <= '{year}-12-31'"
        
        # ã‚¿ã‚°æ¡ä»¶ã‚’æ§‹ç¯‰
        tag_condition = ""
        if tags:
            tag_checks = " OR ".join([f"qa.tags ? '{tag}'" for tag in tags])
            tag_condition = f"AND ({tag_checks})"
        
        # æ¤œç´¢æ¡ä»¶ã‚’æ§‹ç¯‰ï¼ˆSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–å¼·åŒ–ï¼‰
        search_condition = ""
        search_params = {}
        if search:
            # å±é™ºãªæ–‡å­—ã‚’é™¤å»
            search_term = search.replace("'", "").replace(";", "").replace("--", "").replace("/*", "").replace("*/", "")
            # é•·ã•åˆ¶é™ï¼ˆ100æ–‡å­—ã¾ã§ï¼‰
            search_term = search_term[:100] if len(search_term) > 100 else search_term
            
            if search_term:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆã®ã¿
                search_condition = f"""AND (
                    LOWER(b.title) LIKE LOWER('%{search_term}%') OR
                    LOWER(b.author) LIKE LOWER('%{search_term}%') OR
                    LOWER(b.publisher) LIKE LOWER('%{search_term}%') OR
                    LOWER(b.isbn) LIKE LOWER('%{search_term}%')
                )"""
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¥
        pagination_clause = ""
        if limit is not None:
            pagination_clause = f"LIMIT {limit}"
            if offset is not None:
                pagination_clause += f" OFFSET {offset}"
        
        # ç·ä»¶æ•°å–å¾—ç”¨SQLï¼ˆæ¤œç´¢æ¡ä»¶ã¨ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ï¼‰
        count_sql = text(f"""
            SELECT COUNT(DISTINCT b.id) as total
            FROM books b
            JOIN book_qiita_mentions bqm ON b.id = bqm.book_id
            JOIN qiita_articles qa ON bqm.article_id = qa.id
            WHERE b.total_mentions > 0
            {date_condition}
            {tag_condition}
            {search_condition}
        """)
        
        count_result = self.db.execute(count_sql).fetchone()
        total_count = int(count_result.total) if count_result else 0
        
        # ç›´æ¥SQLï¼ˆ1å›ã®ã‚¯ã‚¨ãƒªã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰
        # ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¦ã‚½ãƒ¼ãƒˆï¼ˆå…ƒã®get_ranking()ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        sql = text(f"""
            WITH book_stats AS (
                SELECT 
                    b.id, b.isbn, b.title, b.author, b.publisher, b.publication_date,
                    b.description, b.thumbnail_url, b.amazon_url, b.amazon_affiliate_url,
                    b.total_mentions, b.first_mentioned_at,
                    COUNT(DISTINCT bqm.id) as mention_count,
                    COUNT(DISTINCT qa.id) as article_count,
                    COUNT(DISTINCT qa.author_id) as unique_user_count,
                    COALESCE(SUM(qa.likes_count), 0) as total_likes,
                    MAX(bqm.mentioned_at) as latest_mention_at
                FROM books b
                JOIN book_qiita_mentions bqm ON b.id = bqm.book_id
                JOIN qiita_articles qa ON bqm.article_id = qa.id
                WHERE b.total_mentions > 0
                {date_condition}
                {tag_condition}
                {search_condition}
                GROUP BY b.id, b.isbn, b.title, b.author, b.publisher, b.publication_date,
                         b.description, b.thumbnail_url, b.amazon_url, b.amazon_affiliate_url,
                         b.total_mentions, b.first_mentioned_at
            )
            SELECT 
                *,
                -- å“è³ªé‡è¦–ã‚¹ã‚³ã‚¢: unique_user_count * (1 + ln(avg_likes + 1))
                unique_user_count * (1 + LN(CASE WHEN article_count > 0 THEN (total_likes::float / article_count) + 1 ELSE 1 END)) as calculated_score
            FROM book_stats
            ORDER BY calculated_score DESC
            {pagination_clause}
        """)
        
        results = self.db.execute(sql).fetchall()
        
        # å–å¾—ã—ãŸæ›¸ç±IDã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        book_ids = [row.id for row in results]
        
        # ãƒˆãƒƒãƒ—è¨˜äº‹ã‚’ä¸€æ‹¬å–å¾—ï¼ˆ2å›ç›®ã®ã‚¯ã‚¨ãƒªï¼‰
        top_articles_map: dict[int, list[dict]] = {}
        if book_ids:
            # WINDOWé–¢æ•°ã§ãƒˆãƒƒãƒ—3è¨˜äº‹ã‚’ä¸€æ‹¬å–å¾—
            articles_sql = text(f"""
                WITH ranked_articles AS (
                    SELECT 
                        bqm.book_id,
                        qa.id,
                        qa.qiita_id,
                        qa.title,
                        qa.url,
                        qa.author_id,
                        qa.author_name,
                        qa.likes_count,
                        qa.published_at,
                        ROW_NUMBER() OVER (PARTITION BY bqm.book_id ORDER BY qa.likes_count DESC) as rn
                    FROM book_qiita_mentions bqm
                    JOIN qiita_articles qa ON bqm.article_id = qa.id
                    WHERE bqm.book_id = ANY(:book_ids)
                    {date_condition}
                    {tag_condition}
                )
                SELECT * FROM ranked_articles WHERE rn <= 3
                ORDER BY book_id, rn
            """)
            
            articles_results = self.db.execute(articles_sql, {"book_ids": book_ids}).fetchall()
            
            # book_idåˆ¥ã«ãƒˆãƒƒãƒ—è¨˜äº‹ã‚’æ•´ç†
            for article in articles_results:
                if article.book_id not in top_articles_map:
                    top_articles_map[article.book_id] = []
                
                top_articles_map[article.book_id].append({
                    "id": article.id,
                    "qiita_id": article.qiita_id,
                    "title": article.title,
                    "url": article.url,
                    "author_id": article.author_id,
                    "author_name": article.author_name,
                    "likes_count": article.likes_count,
                    "published_at": article.published_at.isoformat() if article.published_at else None,
                })
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã«æ•´å½¢
        rankings = []
        now = datetime.now()
        for rank, row in enumerate(results, start=1):
            mention_count = int(row.mention_count) if row.mention_count else 0
            article_count = int(row.article_count) if row.article_count else 0
            unique_user_count = int(row.unique_user_count) if row.unique_user_count else 0
            total_likes = int(row.total_likes) if row.total_likes else 0
            avg_likes = total_likes / article_count if article_count > 0 else 0
            
            # ã‚¹ã‚³ã‚¢ï¼ˆSQLã§è¨ˆç®—æ¸ˆã¿ï¼‰
            score = float(row.calculated_score) if hasattr(row, 'calculated_score') else unique_user_count * (1 + math.log(avg_likes + 1))
            
            # NEWãƒãƒƒã‚¸åˆ¤å®š
            is_new = False
            if row.first_mentioned_at:
                days_since_first = (now - row.first_mentioned_at).days
                is_new = days_since_first <= 30
            
            # Amazonã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ç”Ÿæˆ
            amazon_affiliate_url = self.openbd_service.generate_amazon_affiliate_url(row.isbn)
            
            # ãƒˆãƒƒãƒ—è¨˜äº‹ã‚’å–å¾—
            top_articles = top_articles_map.get(row.id, [])
            
            # offsetã‚’è€ƒæ…®ã—ãŸãƒ©ãƒ³ã‚¯è¨ˆç®—
            actual_rank = rank if offset is None else (offset + rank)
            
            rankings.append({
                "rank": actual_rank,
                "book": {
                    "id": row.id,
                    "isbn": row.isbn,
                    "title": row.title,
                    "author": row.author,
                    "publisher": row.publisher,
                    "publication_date": row.publication_date.isoformat() if row.publication_date else None,
                    "description": row.description,
                    "thumbnail_url": row.thumbnail_url,
                    "amazon_url": row.amazon_url,
                    "amazon_affiliate_url": amazon_affiliate_url,
                    "total_mentions": row.total_mentions,
                },
                "stats": {
                    "mention_count": mention_count,
                    "article_count": article_count,
                    "unique_user_count": unique_user_count,
                    "total_likes": total_likes,
                    "avg_likes": round(avg_likes, 2),
                    "score": round(score, 2),
                    "latest_mention_at": row.latest_mention_at.isoformat() if row.latest_mention_at else None,
                    "is_new": is_new,
                },
                "top_articles": top_articles,
            })
        
        result = {
            "rankings": rankings,
            "total": total_count,
            "limit": limit,
            "offset": offset or 0,
        }
        
        # TTLæ±ºå®šï¼ˆå…¨ã¦2-3å€ã«å»¶é•·ï¼‰
        if search:
            # æ¤œç´¢: 1åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåŒã˜æ¤œç´¢ã®é‡è¤‡ã‚’é˜²ãï¼‰
            ttl = 60
        elif days is None and year is None:
            # å…¨æœŸé–“ãƒ©ãƒ³ã‚­ãƒ³ã‚°: 30åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ10åˆ†â†’30åˆ†ï¼‰
            ttl = 1800
        elif days and days >= 30:
            # 30æ—¥ä»¥ä¸Š: 15åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ5åˆ†â†’15åˆ†ï¼‰
            ttl = 900
        elif days and days <= 7:
            # 7æ—¥ä»¥å†…: 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ2åˆ†â†’5åˆ†ï¼‰
            ttl = 300
        elif tags:
            # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿ã‚ã‚Š: 15åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ5åˆ†â†’15åˆ†ï¼‰
            ttl = 900
        else:
            # ãã®ä»–: 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ3åˆ†â†’10åˆ†ï¼‰
            ttl = 600
        
        self.cache.set(cache_key, result, ttl_seconds=ttl)
        cache_type = "æ¤œç´¢" if search else "é€šå¸¸"
        logger.info(f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—å®Œäº†ï¼ˆ{cache_type}ï¼‰: {len(rankings)}/{total_count}ä»¶ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ (TTL: {ttl}s)")
        
        return result
    
    def get_ranking(
        self,
        tags: Optional[List[str]] = None,
        days: Optional[int] = None,
        year: Optional[int] = None,
        month: Optional[int] = None,
        limit: Optional[int] = 100,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ä»¶ã«åˆ¶é™ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
        scoring_method: str = "weighted"
    ) -> List[Dict]:
        """
        æ›¸ç±ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—
        
        Args:
            tags: ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["Python", "JavaScript"]ï¼‰
            days: éå»Næ—¥é–“ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆQiitaè¨˜äº‹ã®published_atåŸºæº–ã€Noneã®å ´åˆã¯å…¨æœŸé–“ï¼‰
            year: ç‰¹å®šã®å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¾‹: 2024ã€Qiitaè¨˜äº‹ãŒæŠ•ç¨¿ã•ã‚ŒãŸå¹´ï¼‰
            month: ç‰¹å®šã®æœˆã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ1-12ã€yearã¨ä½µç”¨ã€Qiitaè¨˜äº‹ãŒæŠ•ç¨¿ã•ã‚ŒãŸæœˆï¼‰
            limit: å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ä»¶ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãŸã‚åˆ¶é™æ¨å¥¨ï¼‰
            scoring_method: ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹å¼
                - "simple": ã‚·ãƒ³ãƒ—ãƒ«ï¼ˆè¨€åŠæ•°ã®ã¿ï¼‰
                - "weighted": åŠ é‡ã‚¹ã‚³ã‚¢ï¼ˆæ¨å¥¨ï¼‰
                - "quality": å“è³ªé‡è¦–
        
        Returns:
            ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆ
        
        Note:
            æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ã¯å®Ÿéš›ã«ãã®æœŸé–“å†…ã«æŠ•ç¨¿ã•ã‚ŒãŸQiitaè¨˜äº‹ã‚’åŸºæº–ã«ã—ã¾ã™ã€‚
            ä¾‹ï¼š2022å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯ã€2022å¹´å†…ã«æŠ•ç¨¿ã•ã‚ŒãŸQiitaè¨˜äº‹ã§è¨€åŠã•ã‚ŒãŸæ›¸ç±ãŒå¯¾è±¡ã€‚
        """
        # åŸºæœ¬ã‚¯ã‚¨ãƒªï¼šæ›¸ç±ã”ã¨ã®è¨€åŠæ•°ã¨ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’é›†è¨ˆ
        query = (
            self.db.query(
                Book.id,
                Book.isbn,
                Book.title,
                Book.author,
                Book.publisher,
                Book.publication_date,
                Book.description,
                Book.thumbnail_url,
                Book.amazon_url,
                Book.amazon_affiliate_url,
                Book.total_mentions,
                Book.first_mentioned_at,
                func.count(BookQiitaMention.id).label('mention_count'),
                func.count(func.distinct(QiitaArticle.id)).label('article_count'),
                func.count(func.distinct(QiitaArticle.author_id)).label('unique_user_count'),  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
                func.sum(QiitaArticle.likes_count).label('total_likes'),
                func.max(BookQiitaMention.mentioned_at).label('latest_mention_at'),
            )
            .join(BookQiitaMention, Book.id == BookQiitaMention.book_id)
            .join(QiitaArticle, BookQiitaMention.article_id == QiitaArticle.id)
        )
        
        # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
        if tags:
            # ã‚¿ã‚°ã®ã„ãšã‚Œã‹ã«ä¸€è‡´ã™ã‚‹è¨˜äº‹ã®ã¿
            tag_conditions = []
            for tag in tags:
                tag_conditions.append(
                    func.jsonb_exists(QiitaArticle.tags, tag)
                )
            if len(tag_conditions) == 1:
                query = query.filter(tag_conditions[0])
            else:
                query = query.filter(func.or_(*tag_conditions))
        
        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆQiitaè¨˜äº‹ã®published_atåŸºæº–ï¼‰
        if days is not None:
            start_date = datetime.now() - timedelta(days=days)
            query = query.filter(QiitaArticle.published_at >= start_date)
        
        # å¹´åˆ¥ãƒ»æœˆåˆ¥ãƒ•ã‚£ãƒ«ã‚¿
        if year is not None:
            from datetime import date
            import calendar
            
            if month is not None:
                # ç‰¹å®šã®å¹´æœˆï¼ˆQiitaè¨˜äº‹ãŒå½“è©²æœˆã«æŠ•ç¨¿ã•ã‚ŒãŸã‚‚ã®ï¼‰
                month_start = date(year, month, 1)
                last_day = calendar.monthrange(year, month)[1]
                month_end = date(year, month, last_day)
                query = query.filter(
                    QiitaArticle.published_at >= month_start,
                    QiitaArticle.published_at <= month_end
                )
            else:
                # å¹´å…¨ä½“ï¼ˆQiitaè¨˜äº‹ãŒå½“è©²å¹´ã«æŠ•ç¨¿ã•ã‚ŒãŸã‚‚ã®ï¼‰
                year_start = date(year, 1, 1)
                year_end = date(year, 12, 31)
                query = query.filter(
                    QiitaArticle.published_at >= year_start,
                    QiitaArticle.published_at <= year_end
                )
        
        # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        query = query.group_by(
            Book.id,
            Book.isbn,
            Book.title,
            Book.author,
            Book.publisher,
            Book.publication_date,
            Book.description,
            Book.thumbnail_url,
            Book.amazon_url,
            Book.amazon_affiliate_url,
            Book.total_mentions,
            Book.first_mentioned_at,
        )
        
        results = query.all()
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—ã¨ã‚½ãƒ¼ãƒˆ
        scored_results = []
        for row in results:
            mention_count = int(row.mention_count) if row.mention_count else 0
            article_count = int(row.article_count) if row.article_count else 0
            unique_user_count = int(row.unique_user_count) if row.unique_user_count else 0
            total_likes = int(row.total_likes) if row.total_likes else 0
            avg_likes = total_likes / article_count if article_count > 0 else 0
            
            # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹å¼ã«å¿œã˜ã¦è¨ˆç®—
            # ã€é‡è¦ã€‘ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’åŸºæº–ã«ã™ã‚‹ã“ã¨ã§ã€1äººãŒå¤§é‡æŠ•ç¨¿ã—ã¦ã‚‚é«˜ã‚¹ã‚³ã‚¢ã«ãªã‚‰ãªã„
            score: float
            if scoring_method == "simple":
                # ã‚·ãƒ³ãƒ—ãƒ«ï¼šãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã®ã¿
                score = float(unique_user_count)
            elif scoring_method == "weighted":
                # åŠ é‡ã‚¹ã‚³ã‚¢
                # ã‚¹ã‚³ã‚¢ = (ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•° Ã— 10) + (ç·ã„ã„ã­æ•° Ã— 0.5) + (å¹³å‡ã„ã„ã­æ•° Ã— 3)
                score = (unique_user_count * 10) + (total_likes * 0.5) + (avg_likes * 3)
            elif scoring_method == "quality":
                # å“è³ªé‡è¦–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                # ã‚¹ã‚³ã‚¢ = ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•° Ã— (1 + log(å¹³å‡ã„ã„ã­æ•° + 1))
                # å¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ”¯æŒã•ã‚Œã€ã‹ã¤ã„ã„ã­æ•°ã‚‚å¤šã„æ›¸ç±ã‚’ä¸Šä½ã«
                score = unique_user_count * (1 + math.log(avg_likes + 1))
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å“è³ªé‡è¦–
                score = unique_user_count * (1 + math.log(avg_likes + 1))
            
            scored_results.append((score, row, avg_likes))
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        scored_results.sort(key=lambda x: x[0], reverse=True)
        
        # ä¸Šä½Nä»¶ã‚’å–å¾—ã¨ã‚¹ã‚³ã‚¢ã‚’ä¿æŒï¼ˆlimitãŒNoneã®å ´åˆã¯å…¨ä»¶ï¼‰
        top_results = scored_results[:limit] if limit is not None else scored_results
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã«æ•´å½¢
        rankings = []
        now = datetime.now()
        for rank, (calculated_score, row, _) in enumerate(top_results, start=1):
            # ã‚¹ã‚³ã‚¢ã¨çµ±è¨ˆæƒ…å ±ã‚’å†è¨ˆç®—
            mention_count = int(row.mention_count) if row.mention_count else 0
            article_count = int(row.article_count) if row.article_count else 0
            unique_user_count = int(row.unique_user_count) if row.unique_user_count else 0
            total_likes = int(row.total_likes) if row.total_likes else 0
            avg_likes = total_likes / article_count if article_count > 0 else 0
            
            # NEWãƒãƒƒã‚¸åˆ¤å®šï¼šåˆç™»å ´ã‹ã‚‰30æ—¥ä»¥å†…
            is_new = False
            if row.first_mentioned_at:
                days_since_first = (now - row.first_mentioned_at).days
                is_new = days_since_first <= 30
            
            # å‹•çš„ã«Amazonã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã‚’ç”Ÿæˆ
            amazon_affiliate_url = self.openbd_service.generate_amazon_affiliate_url(row.isbn)
            
            # ãƒˆãƒƒãƒ—3è¨˜äº‹ã‚’å–å¾—
            top_articles = self._get_top_articles(row.id, tags, days, year, month, limit=3)
            
            rankings.append({
                "rank": rank,
                "book": {
                    "id": row.id,
                    "isbn": row.isbn,
                    "title": row.title,
                    "author": row.author,
                    "publisher": row.publisher,
                    "publication_date": row.publication_date.isoformat() if row.publication_date else None,
                    "description": row.description,
                    "thumbnail_url": row.thumbnail_url,
                    "amazon_url": row.amazon_url,
                    "amazon_affiliate_url": amazon_affiliate_url,  # å‹•çš„ã«ç”Ÿæˆ
                    "total_mentions": row.total_mentions,
                },
                "stats": {
                    "mention_count": mention_count,
                    "article_count": article_count,
                    "unique_user_count": unique_user_count,  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
                    "total_likes": total_likes,
                    "avg_likes": round(avg_likes, 2),  # å¹³å‡ã„ã„ã­æ•°
                    "score": round(calculated_score, 2),  # ã‚¹ã‚³ã‚¢
                    "latest_mention_at": row.latest_mention_at.isoformat() if row.latest_mention_at else None,
                    "is_new": is_new,  # NEWãƒãƒƒã‚¸è¡¨ç¤ºãƒ•ãƒ©ã‚°
                },
                "top_articles": top_articles,  # ãƒˆãƒƒãƒ—3è¨˜äº‹
            })
        
        logger.info(
            f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—å®Œäº†: tags={tags}, days={days}, {len(rankings)}ä»¶"
        )
        
        return rankings
    
    def get_all_tags(self) -> List[Dict]:
        """
        ã™ã¹ã¦ã®ã‚¿ã‚°ã¨ãã®æ›¸ç±æ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥15åˆ†ï¼‰
        
        Returns:
            ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆï¼ˆæ›¸ç±æ•°ã§ã‚½ãƒ¼ãƒˆï¼‰
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        cache_key = "all_tags"
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            logger.info("âœ… ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ")
            return cached_result
        
        logger.info("ğŸ” ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€DBã‚¯ã‚¨ãƒªå®Ÿè¡Œ")
        
        # ã™ã¹ã¦ã®è¨˜äº‹ã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º
        articles = self.db.query(QiitaArticle.tags).all()
        
        # ã‚¿ã‚°ã”ã¨ã«æ›¸ç±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        tag_counts = {}
        for article in articles:
            for tag in article.tags:
                if tag not in tag_counts:
                    tag_counts[tag] = 0
                tag_counts[tag] += 1
        
        # ã‚½ãƒ¼ãƒˆ
        sorted_tags = sorted(
            [{"tag": tag, "book_count": count} for tag, count in tag_counts.items()],
            key=lambda x: x["book_count"],
            reverse=True
        )
        
        # 15åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ›´æ–°é »åº¦ä½ã„ï¼‰
        self.cache.set(cache_key, sorted_tags, ttl_seconds=900)
        logger.info(f"ã‚¿ã‚°ãƒªã‚¹ãƒˆå–å¾—å®Œäº†: {len(sorted_tags)}ä»¶ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ (TTL: 900s)")
        
        return sorted_tags
    
    def _get_top_articles(
        self,
        book_id: int,
        tags: Optional[List[str]] = None,
        days: Optional[int] = None,
        year: Optional[int] = None,
        month: Optional[int] = None,
        limit: int = 3
    ) -> List[Dict]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ›¸ç±ã®ãƒˆãƒƒãƒ—Nè¨˜äº‹ã‚’å–å¾—ï¼ˆã„ã„ã­æ•°é †ï¼‰
        
        Args:
            book_id: æ›¸ç±ID
            tags: ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
            days: æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ—¥æ•°ï¼‰
            year: å¹´ãƒ•ã‚£ãƒ«ã‚¿
            month: æœˆãƒ•ã‚£ãƒ«ã‚¿
            limit: å–å¾—ä»¶æ•°
        
        Returns:
            ãƒˆãƒƒãƒ—Nè¨˜äº‹ã®ãƒªã‚¹ãƒˆ
        """
        query = (
            self.db.query(QiitaArticle)
            .join(BookQiitaMention, BookQiitaMention.article_id == QiitaArticle.id)
            .filter(BookQiitaMention.book_id == book_id)
        )
        
        # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
        if tags:
            tag_conditions = []
            for tag in tags:
                tag_conditions.append(func.jsonb_exists(QiitaArticle.tags, tag))
            if len(tag_conditions) == 1:
                query = query.filter(tag_conditions[0])
            else:
                query = query.filter(func.or_(*tag_conditions))
        
        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿
        if days is not None:
            start_date = datetime.now() - timedelta(days=days)
            query = query.filter(QiitaArticle.published_at >= start_date)
        
        # å¹´åˆ¥ãƒ»æœˆåˆ¥ãƒ•ã‚£ãƒ«ã‚¿
        if year is not None:
            from datetime import date
            import calendar
            
            if month is not None:
                month_start = date(year, month, 1)
                last_day = calendar.monthrange(year, month)[1]
                month_end = date(year, month, last_day)
                query = query.filter(
                    QiitaArticle.published_at >= month_start,
                    QiitaArticle.published_at <= month_end
                )
            else:
                year_start = date(year, 1, 1)
                year_end = date(year, 12, 31)
                query = query.filter(
                    QiitaArticle.published_at >= year_start,
                    QiitaArticle.published_at <= year_end
                )
        
        # ã„ã„ã­æ•°é †ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½Nä»¶ã‚’å–å¾—
        articles = query.order_by(QiitaArticle.likes_count.desc()).limit(limit).all()
        
        # çµæœã‚’æ•´å½¢
        result = []
        for article in articles:
            result.append({
                "id": article.id,
                "title": article.title,
                "url": article.url,
                "author_id": article.author_id,
                "author_name": article.author_name,
                "likes_count": article.likes_count,
                "published_at": article.published_at.isoformat() if article.published_at else None,
            })
        
        return result
    
    def get_available_years(self) -> List[int]:
        """
        ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å¹´ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆé«˜é€Ÿç‰ˆï¼šç›´æ¥SQLä½¿ç”¨ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥15åˆ†ï¼‰
        
        Returns:
            å¹´ã®ãƒªã‚¹ãƒˆï¼ˆé™é †ï¼‰
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        cache_key = "available_years"
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            logger.info("âœ… å¹´ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ")
            return cached_result
        
        logger.info("ğŸ” å¹´ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€DBã‚¯ã‚¨ãƒªå®Ÿè¡Œ")
        
        # ç›´æ¥SQLã§é«˜é€ŸåŒ–
        sql = text("""
            SELECT DISTINCT EXTRACT(YEAR FROM published_at)::int as year
            FROM qiita_articles
            WHERE published_at IS NOT NULL
            ORDER BY year DESC
        """)
        
        results = self.db.execute(sql).fetchall()
        years = [int(row.year) for row in results if row.year]
        
        # 15åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ›´æ–°é »åº¦ä½ã„ï¼‰
        self.cache.set(cache_key, years, ttl_seconds=900)
        logger.info(f"å¹´ãƒªã‚¹ãƒˆå–å¾—å®Œäº†: {len(years)}ä»¶ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ (TTL: 900s)")
        
        return years


# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def get_ranking_service(db: Session) -> RankingService:
    """RankingServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return RankingService(db)
