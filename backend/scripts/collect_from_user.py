#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç‰¹å®šQiitaãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ã‹ã‚‰æ›¸ç±æƒ…å ±ã‚’åé›†
"""

import sys
import os
from pathlib import Path

backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

import logging
import argparse
from typing import Optional
from datetime import datetime
from sqlalchemy.orm import Session

from app.database import SessionLocal
from app.models.qiita_article import QiitaArticle
from app.models.book import Book, BookQiitaMention
from app.services.qiita_service import get_qiita_service
from app.services.openbd_service import get_openbd_service

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)


def get_user_articles(user_id: str, max_articles: int = 100):
    """
    ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ã‚’å–å¾—
    """
    qiita_service = get_qiita_service()
    
    import requests
    import time
    
    all_articles = []
    page = 1
    
    logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ @{user_id} ã®è¨˜äº‹ã‚’å–å¾—ä¸­...")
    
    while len(all_articles) < max_articles:
        try:
            response = requests.get(
                f'https://qiita.com/api/v2/users/{user_id}/items',
                headers={'Authorization': f'Bearer {qiita_service.token}'},
                params={'page': page, 'per_page': 100}
            )
            
            if response.status_code == 404:
                logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ @{user_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            response.raise_for_status()
            articles = response.json()
            
            if not articles:
                break
            
            for article_data in articles:
                article = qiita_service._extract_article_info(article_data)
                all_articles.append(article)
            
            logger.info(f"  âœ“ {len(all_articles)}ä»¶å–å¾—ï¼ˆPage {page}ï¼‰")
            
            if len(articles) < 100:
                break
            
            page += 1
            time.sleep(3.6)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    logger.info(f"âœ… åˆè¨ˆ {len(all_articles)}ä»¶ã®è¨˜äº‹ã‚’å–å¾—")
    return all_articles[:max_articles]


def get_or_create_article(db: Session, article_data: dict) -> QiitaArticle:
    """Qiitaè¨˜äº‹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    qiita_id = article_data['qiita_id']
    
    existing_article = db.query(QiitaArticle).filter(QiitaArticle.qiita_id == qiita_id).first()
    
    if existing_article:
        existing_article.likes_count = article_data.get('likes_count', 0)
        existing_article.stocks_count = article_data.get('stocks_count', 0)
        existing_article.comments_count = article_data.get('comments_count', 0)
        existing_article.updated_at = datetime.now()
        db.commit()
        db.refresh(existing_article)
        return existing_article
    
    new_article = QiitaArticle(
        qiita_id=qiita_id,
        title=article_data.get('title', ''),
        url=article_data.get('url', ''),
        author_id=article_data.get('author_id', ''),
        author_name=article_data.get('author_name'),
        tags=article_data.get('tags', []),
        likes_count=article_data.get('likes_count', 0),
        stocks_count=article_data.get('stocks_count', 0),
        comments_count=article_data.get('comments_count', 0),
        book_mention_count=0,
        published_at=article_data.get('published_at', datetime.now()),
    )
    
    db.add(new_article)
    db.commit()
    db.refresh(new_article)
    
    return new_article


def normalize_isbn(isbn: str) -> str:
    """ISBNã‚’æ­£è¦åŒ–"""
    return isbn.replace('-', '').replace(' ', '')


def get_or_create_book(db: Session, isbn: str, openbd_service) -> Optional[Book]:
    """æ›¸ç±ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    normalized_isbn = normalize_isbn(isbn)
    
    # æ—¢å­˜ã®æ›¸ç±ã‚’æ¤œç´¢
    existing_book = db.query(Book).filter(Book.isbn == normalized_isbn).first()
    if existing_book:
        return existing_book
    
    # openBDã‹ã‚‰æ›¸ç±æƒ…å ±ã‚’å–å¾—
    book_info = openbd_service.get_book_info(normalized_isbn)
    
    if not book_info:
        logger.warning(f"  âš  ISBN {normalized_isbn}: openBDã§è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    # æ–°ã—ã„æ›¸ç±ã‚’ä½œæˆ
    new_book = Book(
        isbn=normalized_isbn,
        title=book_info.get('title', f'ISBN: {normalized_isbn}'),
        author=book_info.get('author'),
        publisher=book_info.get('publisher'),
        publication_date=book_info.get('publication_date'),
        description=book_info.get('description'),
        thumbnail_url=book_info.get('thumbnail_url'),
        amazon_url=openbd_service.generate_amazon_url(normalized_isbn),
        amazon_affiliate_url=openbd_service.generate_amazon_affiliate_url(normalized_isbn),
        book_data=book_info,
    )
    
    db.add(new_book)
    db.commit()
    db.refresh(new_book)
    
    logger.info(f"  âœ“ æ–°è¦æ›¸ç±: {new_book.title[:40]}...")
    return new_book


def main():
    parser = argparse.ArgumentParser(description='ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ã‹ã‚‰æ›¸ç±æƒ…å ±ã‚’åé›†')
    parser.add_argument('--user', required=True, help='Qiitaãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä¾‹: sappuruã•ã‚“ï¼‰')
    parser.add_argument('--max-articles', type=int, default=100, help='æœ€å¤§è¨˜äº‹æ•°')
    
    args = parser.parse_args()
    
    logger.info("=" * 80)
    logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ @{args.user} ã®è¨˜äº‹ã‹ã‚‰æ›¸ç±æƒ…å ±ã‚’åé›†")
    logger.info("=" * 80)
    
    qiita_service = get_qiita_service()
    openbd_service = get_openbd_service()
    db = SessionLocal()
    
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜äº‹ã‚’å–å¾—
        articles = get_user_articles(args.user, args.max_articles)
        
        if not articles:
            logger.error("è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # æ›¸ç±ãƒªãƒ³ã‚¯ã‚’å«ã‚€è¨˜äº‹ã‚’å‡¦ç†
        total_books = 0
        total_mentions = 0
        
        for article in articles:
            body = article.get('body', '')
            book_refs = qiita_service.extract_book_references(body)
            
            if not book_refs:
                continue
            
            logger.info(f"\nğŸ“„ è¨˜äº‹: {article['title'][:50]}...")
            logger.info(f"   æ›¸ç±ãƒªãƒ³ã‚¯: {len(book_refs)}ä»¶")
            
            # è¨˜äº‹ã‚’DBã«ä¿å­˜
            qiita_article = get_or_create_article(db, article)
            
            # å„æ›¸ç±ã‚’å‡¦ç†
            for isbn in book_refs:
                book = get_or_create_book(db, isbn, openbd_service)
                
                if book:
                    # è¨€åŠã‚’ä¿å­˜
                    existing_mention = db.query(BookQiitaMention).filter(
                        BookQiitaMention.book_id == book.id,
                        BookQiitaMention.qiita_article_id == qiita_article.id
                    ).first()
                    
                    if not existing_mention:
                        mention = BookQiitaMention(
                            book_id=book.id,
                            qiita_article_id=qiita_article.id,
                            mentioned_at=qiita_article.published_at
                        )
                        db.add(mention)
                        total_mentions += 1
                    
                    total_books += 1
            
            db.commit()
        
        logger.info("\n" + "=" * 80)
        logger.info("âœ… åé›†å®Œäº†ï¼")
        logger.info("=" * 80)
        logger.info(f"å‡¦ç†ã—ãŸè¨˜äº‹: {len(articles)}ä»¶")
        logger.info(f"åé›†ã—ãŸæ›¸ç±: {total_books}ä»¶")
        logger.info(f"æ–°è¦è¨€åŠ: {total_mentions}ä»¶")
        logger.info("=" * 80)
        
    finally:
        db.close()


if __name__ == '__main__':
    main()

